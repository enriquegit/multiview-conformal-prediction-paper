{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33073c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from globals import *\n",
    "from cpfunctions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4049d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file.\n",
    "df = pd.read_csv(FILE_PATH)\n",
    "\n",
    "# Encode labels into integers.\n",
    "le = LabelEncoder()\n",
    "df[\"class\"] = le.fit_transform(df[\"class\"])\n",
    "\n",
    "# Get features, class\n",
    "y = df[\"class\"]\n",
    "\n",
    "# Drop the label.\n",
    "X = df.drop([\"class\"], axis = 1)\n",
    "\n",
    "# Get column names.\n",
    "colnames = list(X.columns)\n",
    "\n",
    "# Save classes order.\n",
    "save_classes_order(pd.DataFrame(le.classes_), DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff576fa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Arrays to store results.\n",
    "it = []\n",
    "method = []\n",
    "groundTruth = []\n",
    "prediction = []\n",
    "predictionSet = []\n",
    "scores = [] # prediction scores as produced by the underlying model.\n",
    "pvalues = []\n",
    "\n",
    "for i in range(ITERATIONS):\n",
    "\n",
    "    curr_it = 1 + i # current iteration.\n",
    "    \n",
    "    print(\"Iteration \" + str(curr_it))\n",
    "\n",
    "    # Set random seed. This should be updated based on iteration number.\n",
    "    random_seed = 100 + curr_it\n",
    "\n",
    "    # Split into train, calibration, and test sets.\n",
    "    X_train, X_rest, y_train, y_rest = train_test_split(X, y,\n",
    "                                                        train_size = PCT_TRAIN, \n",
    "                                                        stratify = y, \n",
    "                                                        random_state = random_seed)\n",
    "\n",
    "    X_calib, X_test, y_calib, y_test = train_test_split(X_rest, y_rest,\n",
    "                                                        train_size = PCT_CALIBRATION,\n",
    "                                                        stratify = y_rest,\n",
    "                                                        random_state = random_seed)\n",
    "\n",
    "\n",
    "    # Fit the models\n",
    "    classifiers = fit_models_2v(X_train, y_train, random_seed)\n",
    "    \n",
    "    # Build the conformal models.\n",
    "    for model in classifiers:\n",
    "        \n",
    "        modeltype = model[0]\n",
    "        \n",
    "        cp = MapieClassifier(estimator=model[1],\n",
    "                               cv=\"prefit\",\n",
    "                               method=\"score\",\n",
    "                               random_state=random_seed,\n",
    "                               n_jobs=NUMCORES)\n",
    "\n",
    "        if modeltype in ['v1','v2','v3']:\n",
    "            selectedcols = [x for x in colnames if modeltype + '_' in x]\n",
    "        elif modeltype == \"aggregated\":\n",
    "            selectedcols = colnames\n",
    "        elif modeltype == \"mvcs\":\n",
    "            selectedcols = colnames\n",
    "    \n",
    "        cp.fit(X_calib.loc[:, selectedcols], y_calib)\n",
    "\n",
    "        y_pred, y_set = cp.predict(X_test.loc[:, selectedcols], alpha=ALPHA)\n",
    "\n",
    "        y_set = np.squeeze(y_set)\n",
    "\n",
    "        #### Append results ####\n",
    "        n = len(y_pred)\n",
    "\n",
    "        # Iteration\n",
    "        tmp = np.empty(n, dtype=int)\n",
    "        tmp.fill(curr_it)\n",
    "        it.extend(tmp)\n",
    "\n",
    "        # Method name\n",
    "        method.extend([model[0]] * n)\n",
    "\n",
    "        # Ground truth\n",
    "        groundTruth.extend(le.inverse_transform(y_test))\n",
    "\n",
    "        # Prediction\n",
    "        prediction.extend(le.inverse_transform(y_pred))\n",
    "\n",
    "        # Prediction set.\n",
    "        predictionSet.extend([\"|\".join(le.classes_[y_set[i]]) for i in range(n)])\n",
    "\n",
    "        # Predicted scores.\n",
    "        pred_scores = model[1].predict_proba(X_test.loc[:, selectedcols])\n",
    "        scores.extend([\"|\".join(pred_scores[i,y_set[i]].astype(str)) for i in range(n)])\n",
    "        \n",
    "        # Compute p-values.\n",
    "        cal_probs = model[1].predict_proba(X_calib.loc[:, selectedcols])\n",
    "        prob_true_class = cal_probs[np.arange(len(X_calib.loc[:, selectedcols])),y_calib]\n",
    "        calib_scores = 1 - prob_true_class\n",
    "        test_scores = 1 - pred_scores\n",
    "        arr_pvalues = compute_pvalues(calib_scores, test_scores)\n",
    "        pvalues.extend([\"|\".join(arr_pvalues[i,:].astype(str)) for i in range(n)])\n",
    "\n",
    "# Store results in data frame.\n",
    "d = {'it': it, 'method': method, \n",
    "     'groundTruth': groundTruth,\n",
    "     'prediction': prediction,\n",
    "     'predictionSet': predictionSet,\n",
    "     'scores': scores,\n",
    "     'pvalues': pvalues}\n",
    "\n",
    "results = pd.DataFrame(d)\n",
    "\n",
    "save_df(results, DATASET_PATH, \"1\", \"results.csv\")\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8735018d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
